{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "500dcd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "830f8620-435f-4b42-9bf9-e7bc9f76c688",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/girasen/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/girasen/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/girasen/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /Users/girasen/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download(\"omw-1.4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "87f731d9-d9b6-4d04-b36e-b9c7742d1641",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading and splitting the dataset between train and test\n",
    "org_df=pd.read_csv('Mental_health.csv')\n",
    "\n",
    "data=org_df.dropna(how='all')\n",
    "data=data.dropna()\n",
    "data = data.dropna().reset_index(drop=True)\n",
    "# X=org_df['statement']\n",
    "# y=org_df['status']\n",
    "# X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=40)\n",
    "# print(data.loc[2,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "34901c08-0ac7-4da2-aa39-968671dff085",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing of the data\n",
    "wnl=WordNetLemmatizer()\n",
    "stop_words=set(stopwords.words('english'))\n",
    "for i in range(len(data)):\n",
    "    # print(data.iloc[i,1])\n",
    "    data.iloc[i,1]=re.sub(r'[^a-zA-Z0-9\\s]','',data.iloc[i,1].lower())\n",
    "    data.iloc[i,1]=re.sub(r'\\s',' ',data.iloc[i,1])\n",
    "    word_tokens=word_tokenize(str(data.iloc[i,1]))\n",
    "    filtered_stop_words=[x for x in word_tokens if x not in stop_words]\n",
    "    lemmatized_words=[wnl.lemmatize(x,pos=\"v\") for x in filtered_stop_words]\n",
    "    data.iloc[i,1]=' '.join(lemmatized_words)\n",
    "    # print(data.iloc[i,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5798fc98-f209-4b72-adad-6e90a9adff0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70222\n"
     ]
    }
   ],
   "source": [
    "#Building vocabulary list from the dataset\n",
    "tokenize_words=[word_tokenize(i) for i in data['statement']]\n",
    "vocabulary=set()\n",
    "for sentence in tokenize_words:\n",
    "    vocabulary.update(sentence)\n",
    "vocab=sorted(list(vocabulary))\n",
    "# print(len(vocab))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a2ccf1-defb-4c09-b7ee-10b143542e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating bag of words\n",
    "def create_bow(sentence,vocab):\n",
    "    vector=[0]*len(vocab)\n",
    "    for i in sentence:\n",
    "        if i in vocab:\n",
    "            idx=vocab.index(i)\n",
    "            vector[idx]+=1\n",
    "    return vector\n",
    "\n",
    "vectors=[create_bow(sentence,vocab) for sentence in tokenize_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e06ba7ac-677a-4e8f-bb8b-1874c35ce5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7697b39d-1142-4aa5-b7af-203a90bf1896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: ['00' '000' '0000' ... 'zzzz' 'zzzzzz' 'zzzzzzzzz']\n",
      "Array representation:\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "merged_sentences=[' '.join(i) for i in tokenize_words]\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(merged_sentences)\n",
    "print(\"Vocabulary:\", tfidf_vectorizer.get_feature_names_out())\n",
    "print(\"Array representation:\") \n",
    "print(X_tfidf.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "51281be6-c5df-4e0e-b7a9-f2d037570af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "label=[i for i in data['status']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2c46b13c-5c21-4815-9694-89d3823be0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_labels=list(set(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "634d7c04-31ff-4d83-8617-8c7f2b2a5229",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Added label column\n",
    "data['label'] = pd.factorize(data['status'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8fc06961-cb75-44d7-88fe-422d86f7da8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>statement</th>\n",
       "      <th>status</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>oh gosh</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>trouble sleep confuse mind restless heart tune</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>wrong back dear forward doubt stay restless re...</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ive shift focus something else im still worry</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>im restless restless month boy mean</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                          statement   status  \\\n",
       "0           0                                            oh gosh  Anxiety   \n",
       "1           1     trouble sleep confuse mind restless heart tune  Anxiety   \n",
       "2           2  wrong back dear forward doubt stay restless re...  Anxiety   \n",
       "3           3      ive shift focus something else im still worry  Anxiety   \n",
       "4           4                im restless restless month boy mean  Anxiety   \n",
       "\n",
       "   label  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f324567d-cf5b-4597-aec0-7762b1cb1818",
   "metadata": {},
   "outputs": [],
   "source": [
    "f"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
