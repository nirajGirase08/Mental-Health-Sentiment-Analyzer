{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "500dcd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "830f8620-435f-4b42-9bf9-e7bc9f76c688",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/girasen/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/girasen/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/girasen/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /Users/girasen/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download(\"omw-1.4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "87f731d9-d9b6-4d04-b36e-b9c7742d1641",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading and splitting the dataset between train and test\n",
    "org_df=pd.read_csv('Mental_health.csv')\n",
    "data=org_df.dropna(how='all')\n",
    "data=data.dropna()\n",
    "data = data.dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "34901c08-0ac7-4da2-aa39-968671dff085",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing of the data\n",
    "wnl=WordNetLemmatizer()\n",
    "stop_words=set(stopwords.words('english'))\n",
    "for i in range(len(data)):\n",
    "    data.iloc[i,1]=re.sub(r'[^a-zA-Z0-9\\s]','',data.iloc[i,1].lower())\n",
    "    data.iloc[i,1]=re.sub(r'\\s',' ',data.iloc[i,1])\n",
    "    word_tokens=word_tokenize(str(data.iloc[i,1]))\n",
    "    filtered_stop_words=[x for x in word_tokens if x not in stop_words]\n",
    "    lemmatized_words=[wnl.lemmatize(x,pos=\"v\") for x in filtered_stop_words]\n",
    "    data.iloc[i,1]=' '.join(lemmatized_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5798fc98-f209-4b72-adad-6e90a9adff0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building vocabulary list from the dataset\n",
    "tokenize_words=[word_tokenize(i) for i in data['statement']]\n",
    "vocabulary=set()\n",
    "for sentence in tokenize_words:\n",
    "    vocabulary.update(sentence)\n",
    "vocab=sorted(list(vocabulary))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a2ccf1-defb-4c09-b7ee-10b143542e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating bag of words\n",
    "def create_bow(sentence,vocab):\n",
    "    vector=[0]*len(vocab)\n",
    "    for i in sentence:\n",
    "        if i in vocab:\n",
    "            idx=vocab.index(i)\n",
    "            vector[idx]+=1\n",
    "    return vector\n",
    "\n",
    "vectors=[create_bow(sentence,vocab) for sentence in tokenize_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7697b39d-1142-4aa5-b7af-203a90bf1896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: ['00' '000' '0000' ... 'zzzz' 'zzzzzz' 'zzzzzzzzz']\n",
      "Array representation:\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "#Using TF-IDF vectorization\n",
    "merged_sentences=[' '.join(i) for i in tokenize_words]\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(merged_sentences)\n",
    "print(\"Vocabulary:\", tfidf_vectorizer.get_feature_names_out())\n",
    "print(\"Array representation:\") \n",
    "print(X_tfidf.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "51281be6-c5df-4e0e-b7a9-f2d037570af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a  numeric label column\n",
    "label=[i for i in data['status']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2c46b13c-5c21-4815-9694-89d3823be0f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Normal', 'Stress', 'Suicidal', 'Anxiety', 'Bipolar', 'Personality disorder', 'Depression']\n"
     ]
    }
   ],
   "source": [
    "#Printing unique labels(sentiments) in the data\n",
    "unique_labels=list(set(label))\n",
    "print(unique_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "634d7c04-31ff-4d83-8617-8c7f2b2a5229",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding a label column\n",
    "data['label'] = pd.factorize(data['status'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8fc06961-cb75-44d7-88fe-422d86f7da8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>statement</th>\n",
       "      <th>status</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>oh gosh</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>trouble sleep confuse mind restless heart tune</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>wrong back dear forward doubt stay restless re...</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ive shift focus something else im still worry</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>im restless restless month boy mean</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                          statement   status  \\\n",
       "0           0                                            oh gosh  Anxiety   \n",
       "1           1     trouble sleep confuse mind restless heart tune  Anxiety   \n",
       "2           2  wrong back dear forward doubt stay restless re...  Anxiety   \n",
       "3           3      ive shift focus something else im still worry  Anxiety   \n",
       "4           4                im restless restless month boy mean  Anxiety   \n",
       "\n",
       "   label  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f324567d-cf5b-4597-aec0-7762b1cb1818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42144,)\n"
     ]
    }
   ],
   "source": [
    "#Splitting the TF-IDF data for train and test \n",
    "X=X_tfidf\n",
    "y=data['label']\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f69b2b54-b66d-42a6-8161-813a5d7a7070",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implementing Random forest \n",
    "rf_model=RandomForestClassifier(n_estimators=200,random_state=40)\n",
    "#Fit the model for training data\n",
    "rf_model.fit(X_train,y_train)\n",
    "#Predict it on the test data\n",
    "y_pred=rf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "33fa299a-1cb0-4ec4-a37e-c4363194fe7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.6950744993831262\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.56      0.69       767\n",
      "           1       0.80      0.95      0.87      3263\n",
      "           2       0.56      0.81      0.66      3147\n",
      "           3       0.68      0.41      0.51      2040\n",
      "           4       1.00      0.21      0.35       541\n",
      "           5       0.99      0.40      0.57       593\n",
      "           6       1.00      0.29      0.45       186\n",
      "\n",
      "    accuracy                           0.70     10537\n",
      "   macro avg       0.85      0.52      0.59     10537\n",
      "weighted avg       0.74      0.70      0.67     10537\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Accuracy and classification report\n",
    "accuracy_rep=accuracy_score(y_test,y_pred)\n",
    "classification_rep=classification_report(y_test,y_pred)\n",
    "print('Accuracy: ', accuracy_rep)\n",
    "print('Classification report: ')\n",
    "print(classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7708cc44-178d-46e0-91c9-528a3d4eb2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing count vecotrizer to check if the accuracy can be improved\n",
    "count_vectorizer = CountVectorizer()\n",
    "X = count_vectorizer.fit_transform(merged_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2dfdf041-6e53-4837-9244-d1221def8de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a8286173-a3db-4eee-a06a-f202aaa71f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model=RandomForestClassifier(n_estimators=200,random_state=40)\n",
    "#Fit the model for training data\n",
    "rf_model.fit(X_train,y_train)\n",
    "#Predict it on the test data\n",
    "y_pred=rf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "9f0ce142-8c6d-4d1f-b719-f5a839260686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.6879567239252159\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.52      0.66       767\n",
      "           1       0.79      0.95      0.86      3263\n",
      "           2       0.56      0.81      0.66      3147\n",
      "           3       0.67      0.41      0.51      2040\n",
      "           4       1.00      0.21      0.35       541\n",
      "           5       0.99      0.38      0.55       593\n",
      "           6       1.00      0.30      0.46       186\n",
      "\n",
      "    accuracy                           0.69     10537\n",
      "   macro avg       0.84      0.51      0.58     10537\n",
      "weighted avg       0.73      0.69      0.67     10537\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy_rep=accuracy_score(y_test,y_pred)\n",
    "classification_rep=classification_report(y_test,y_pred)\n",
    "print('Accuracy: ', accuracy_rep)\n",
    "print('Classification report: ')\n",
    "print(classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "4f07e608-ad9e-4afa-b76a-aef1ff5b3ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "#Predict a sentence\n",
    "def predict_sentence(sen):\n",
    "    sen=re.sub(r'[^a-zA-Z0-9\\s]','',sen.lower())\n",
    "    sen=re.sub(r'\\s',' ',sen)\n",
    "    word_tokens=word_tokenize(sen)\n",
    "    filtered_stop_words=[x for x in word_tokens if x not in stop_words]\n",
    "    lemmatized_words=[wnl.lemmatize(x,pos=\"v\") for x in filtered_stop_words]\n",
    "    sen=' '.join(lemmatized_words)\n",
    "    return sen\n",
    "sen=predict_sentence(\"I have too much trouble while sleeping and my mind is always confused and restless!\")\n",
    "count_vec_pred = count_vectorizer.transform([sen])\n",
    "pred_class=rf_model.predict(count_vec_pred)\n",
    "print(pred_class)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
