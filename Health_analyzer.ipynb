{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "500dcd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "830f8620-435f-4b42-9bf9-e7bc9f76c688",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/girasen/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/girasen/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/girasen/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /Users/girasen/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download(\"omw-1.4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87f731d9-d9b6-4d04-b36e-b9c7742d1641",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading and splitting the dataset between train and test\n",
    "org_df=pd.read_csv('Mental_health.csv')\n",
    "data=org_df.dropna(how='all')\n",
    "data=data.dropna()\n",
    "data = data.dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34901c08-0ac7-4da2-aa39-968671dff085",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing of the data\n",
    "wnl=WordNetLemmatizer()\n",
    "stop_words=set(stopwords.words('english'))\n",
    "for i in range(len(data)):\n",
    "    data.iloc[i,1]=re.sub(r'[^a-zA-Z0-9\\s]','',data.iloc[i,1].lower())\n",
    "    data.iloc[i,1]=re.sub(r'\\s',' ',data.iloc[i,1])\n",
    "    word_tokens=word_tokenize(str(data.iloc[i,1]))\n",
    "    filtered_stop_words=[x for x in word_tokens if x not in stop_words]\n",
    "    lemmatized_words=[wnl.lemmatize(x,pos=\"v\") for x in filtered_stop_words]\n",
    "    data.iloc[i,1]=' '.join(lemmatized_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5798fc98-f209-4b72-adad-6e90a9adff0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building vocabulary list from the dataset\n",
    "tokenize_words=[word_tokenize(i) for i in data['statement']]\n",
    "vocabulary=set()\n",
    "for sentence in tokenize_words:\n",
    "    vocabulary.update(sentence)\n",
    "vocab=sorted(list(vocabulary))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58a2ccf1-defb-4c09-b7ee-10b143542e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating bag of words\n",
    "def create_bow(sentence,vocab):\n",
    "    vector=[0]*len(vocab)\n",
    "    for i in sentence:\n",
    "        if i in vocab:\n",
    "            idx=vocab.index(i)\n",
    "            vector[idx]+=1\n",
    "    return vector\n",
    "\n",
    "vectors=[create_bow(sentence,vocab) for sentence in tokenize_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7697b39d-1142-4aa5-b7af-203a90bf1896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: ['00' '10' '10 minutes' ... 'zoloft' 'zombie' 'zone']\n",
      "Array representation:\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "#Using TF-IDF vectorization\n",
    "merged_sentences=[' '.join(i) for i in tokenize_words]\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1,2),max_features=5000)\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(merged_sentences)\n",
    "print(\"Vocabulary:\", tfidf_vectorizer.get_feature_names_out())\n",
    "print(\"Array representation:\") \n",
    "print(X_tfidf.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "51281be6-c5df-4e0e-b7a9-f2d037570af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a  numeric label column\n",
    "label=[i for i in data['status']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2c46b13c-5c21-4815-9694-89d3823be0f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Suicidal', 'Depression', 'Personality disorder', 'Bipolar', 'Normal', 'Anxiety', 'Stress']\n"
     ]
    }
   ],
   "source": [
    "#Printing unique labels(sentiments) in the data\n",
    "unique_labels=list(set(label))\n",
    "print(unique_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "634d7c04-31ff-4d83-8617-8c7f2b2a5229",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding a label column\n",
    "data['label'] = pd.factorize(data['status'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8fc06961-cb75-44d7-88fe-422d86f7da8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>statement</th>\n",
       "      <th>status</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>oh my gosh</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>trouble sleeping, confused mind, restless hear...</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>All wrong, back off dear, forward doubt. Stay ...</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>I've shifted my focus to something else but I'...</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>I'm restless and restless, it's been a month n...</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                          statement   status  \\\n",
       "0           0                                         oh my gosh  Anxiety   \n",
       "1           1  trouble sleeping, confused mind, restless hear...  Anxiety   \n",
       "2           2  All wrong, back off dear, forward doubt. Stay ...  Anxiety   \n",
       "3           3  I've shifted my focus to something else but I'...  Anxiety   \n",
       "4           4  I'm restless and restless, it's been a month n...  Anxiety   \n",
       "\n",
       "   label  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f324567d-cf5b-4597-aec0-7762b1cb1818",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the TF-IDF data for train and test \n",
    "X=X_tfidf\n",
    "y=data['label']\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f69b2b54-b66d-42a6-8161-813a5d7a7070",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implementing Random forest \n",
    "rf_model=RandomForestClassifier(n_estimators=100,random_state=40)\n",
    "#Fit the model for training data\n",
    "rf_model.fit(X_train,y_train)\n",
    "#Predict it on the test data\n",
    "y_pred=rf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "33fa299a-1cb0-4ec4-a37e-c4363194fe7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7120622568093385\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.63      0.72       767\n",
      "           1       0.81      0.94      0.87      3263\n",
      "           2       0.59      0.81      0.68      3147\n",
      "           3       0.68      0.44      0.53      2040\n",
      "           4       0.96      0.25      0.39       541\n",
      "           5       0.97      0.52      0.68       593\n",
      "           6       0.98      0.31      0.47       186\n",
      "\n",
      "    accuracy                           0.71     10537\n",
      "   macro avg       0.83      0.56      0.62     10537\n",
      "weighted avg       0.74      0.71      0.70     10537\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Accuracy and classification report\n",
    "accuracy_rep=accuracy_score(y_test,y_pred)\n",
    "classification_rep=classification_report(y_test,y_pred)\n",
    "print('Accuracy: ', accuracy_rep)\n",
    "print('Classification report: ')\n",
    "print(classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7708cc44-178d-46e0-91c9-528a3d4eb2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing count vecotrizer to check if the accuracy can be improved\n",
    "count_vectorizer = CountVectorizer(ngram_range=(1,3))\n",
    "X = count_vectorizer.fit_transform(merged_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2dfdf041-6e53-4837-9244-d1221def8de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22aad66f-8faf-4d8d-94e2-5976de4b0613",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model=RandomForestClassifier(n_estimators=100,random_state=40)\n",
    "#Fit the model for training data\n",
    "rf_model.fit(X_train,y_train)\n",
    "#Predict it on the test data\n",
    "y_pred=rf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0ce142-8c6d-4d1f-b719-f5a839260686",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_rep=accuracy_score(y_test,y_pred)\n",
    "classification_rep=classification_report(y_test,y_pred)\n",
    "print('Accuracy: ', accuracy_rep)\n",
    "print('Classification report: ')\n",
    "print(classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4f07e608-ad9e-4afa-b76a-aef1ff5b3ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "#Predict a sentence\n",
    "def predict_sentence(sen):\n",
    "    sen=re.sub(r'[^a-zA-Z0-9\\s]','',sen.lower())\n",
    "    sen=re.sub(r'\\s',' ',sen)\n",
    "    word_tokens=word_tokenize(sen)\n",
    "    filtered_stop_words=[x for x in word_tokens if x not in stop_words]\n",
    "    lemmatized_words=[wnl.lemmatize(x,pos=\"v\") for x in filtered_stop_words]\n",
    "    sen=' '.join(lemmatized_words)\n",
    "    return sen\n",
    "sen=predict_sentence(\"I am feelig sad!\")\n",
    "count_vec_pred = tfidf_vectorizer.transform([sen])\n",
    "pred_class=rf_model.predict(count_vec_pred)\n",
    "print(pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "74eec8bc-79d3-4744-8af1-e29b17560458",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Implementing transformer for feature extraction and then using ML models on top of that for classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02018c8d-e039-4f83-a91f-17ab5549acc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71e401bc-ca92-455d-a862-eabe04030968",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd525592-e873-460a-a9c3-34cd949d389b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"This is a sample sentence.\"\n",
    "inputs = tokenizer(sentence, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21e7731d-34d5-4cb3-85ec-3093e64b3d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[ 101, 2023, 2003, 1037, 7099, 6251, 1012,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1]])}\n"
     ]
    }
   ],
   "source": [
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e777f21e-d786-4277-a032-fdc8577c43b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 768])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(): outputs = model(**inputs)\n",
    "sentence_embedding = outputs.pooler_output  # Size: [1, 768]\n",
    "print(sentence_embedding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2b808ad-a601-48ff-9f78-eb89cf16eb03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>statement</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>oh my gosh</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>trouble sleeping, confused mind, restless hear...</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>All wrong, back off dear, forward doubt. Stay ...</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>I've shifted my focus to something else but I'...</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>I'm restless and restless, it's been a month n...</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                          statement   status\n",
       "0           0                                         oh my gosh  Anxiety\n",
       "1           1  trouble sleeping, confused mind, restless hear...  Anxiety\n",
       "2           2  All wrong, back off dear, forward doubt. Stay ...  Anxiety\n",
       "3           3  I've shifted my focus to something else but I'...  Anxiety\n",
       "4           4  I'm restless and restless, it's been a month n...  Anxiety"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "55803415-57fc-4799-9a8b-66b96863dcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data['statement']\n",
    "y=data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e39b14f4-cb7d-4479-b28d-166037a64d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1bf307e6-427f-4d47-baca-36e1026b50fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "58459554-7196-46b0-a387-f6d7306f51bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def bert_embedding(sentence):\n",
    "    inputs = tokenizer(sentence, return_tensors='pt',truncation=True, padding=True, max_length=512)\n",
    "    with torch.no_grad(): outputs = model(**inputs)\n",
    "    sentence_embedding = outputs.pooler_output \n",
    "    return sentence_embedding.squeeze().numpy()\n",
    "X_train_embeddings=[bert_embedding(x) for x in X_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0472fc-c527-43ec-873d-723f68b067cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
